---
title: "Week Ten: Inference for Many Means (ANOVA)"
author: ""
output:
  prettydoc::html_pretty:
    theme: tactile
    highlight: github
    css: styles.css
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
library(tidyverse)
library(emo)
library(gridExtra)
```


Welcome!

In this week's coursework we are wrapping up the quarter by investigating how 
we can use the inference we've learned in a new context---comparing multiple 
means. These comparisons have a specific name, ANalysis of VAriance (ANOVA). 


We are going to use all of the simulation-based methods we learned previously 
for this new context. An ANOVA relies on a new statistic, the $F$-statistic, to 
summarize how different 3 or more means are from each other. 

The primary focus of an ANOVA is to detect if the means of 3 or more groups are 
different. Because of this we focus on hypothesis tests for a difference in the 
group means and **do not** use confidence intervals. We will generate
permutation distributions of $F$-statistics that we could have observed
**if the null hypothesis was true** (there is no difference in the group means).


## Learning Outcomes 

By the end of this coursework you should be able to:

- describe what an ANOVA tests for 
- use a visualization to outline how the following are calculated: 
  * total sum of squares
  * group sum of squares
  * residual sum of squares

- describe why the mean squares of groups is called the "between group
variability" 
- describe why the mean square error is called the "within group variability" 
- outline how an F-statistic is calculated
- explain what a "large" or a "small" F-statistic indicates

- describe the conditions for performing an ANOVA procedure
- outline when it is appropriate to use an $F$-distribution in an ANOVA
- explain the similarities and differences between parametric ($F$-based)
methods and non-parametric (simulation-based) methods

- use R to:
  * generate a permutation distribution for F-statistics
  * visualize the permutation distribution
  * calculate the observed F-statistic statistic
  * calculate a p-value for a hypothesis test


---

## This Week's TODOs

`r emo::ji("book")` Reading: 45-60 minutes 

`r emo::ji("computer")` Tutorial: 30-45 minutes

`r emo::ji("paper")` Group Discussion Homework: ANOVA Project  

`r emo::ji("check")` Check-ins: 2

---

## Comparing Multiple Means

### `r emo::ji("book")` [**Required Reading:** *IMS*, Inference for Comparing Many Means](https://openintro-ims.netlify.app/inference-many-means.html)

---

## Randomization Tests for Comparing Many Means

### `r emo::ji("computer")` [Comparing many means with ANOVA - R Tutorial](https://openintro.shinyapps.io/ims-05-infer-08/)

---

## Mathematical Model for Comparing Many Means

### `r emo::ji("check")` Check-in: Components of an ANOVA

1. Which of the following are true about the mean squares between groups?

- it is a standardized measure of the variability in responses between groups
- it compares the mean of each group to the overall mean across all groups
- it compares the observations within each group to the mean of that group
- it is used as the numerator in an F-statistic
- it is used as the denominator in an F-statistic
- it is found by dividing the sum of squares between groups by the number of 
groups minus 1 ($k$ - 1)
- it is found by dividing the sum of squares between groups by the sample size
minus the number of groups ($n - k$)

2. Which of the following are true about the mean square errors?

- it is a standardized measure of the variability in responses within each 
group
- it compares the mean of each group to the overall mean across all groups
- it compares the observations within each group to the mean of that group
- it is used as the numerator in an F-statistic
- it is used as the denominator in an F-statistic
- it is found by dividing the sum of square errors by the number of groups
minus 1 ($k$ - 1)
- it is found by dividing the sum of square errors by the sample size minus 
the number of groups ($n - k$)

3. An F-statistic uses which formula? 

- $\frac{MSG}{MSE}$

- $\frac{SSG}{SSE}$

- $\frac{MSE}{MSG}$

- $\frac{SSE}{SSG}$

4. Ideally, in an ANOVA we'd like to see... (select all that apply)

- large variability in the means of the groups 
- small variability in the means of the groups 
- large variability in the observations within each group
- small variability in the observations within each group

5. If the null hypothesis that the means of four groups are all the same is
rejected using ANOVA at a 5% significance level, then... (select all that apply)

- we can then conclude that all the means are different from one another.

- the variability between groups is higher than the variability within groups.

- the pairwise analysis will identify at least one pair of means that are
significantly different.

- an appropriate $\alpha$ to be used in pairwise comparisons is
$\frac{0.05}{4} = 0.0125$ since there are four groups.
 
---

## Chapter Review 

### `r emo::ji("check")` Check-in: ANOVA Conditions

**These are all true or false questions, so you will be given _one_ attempt for 
this quiz**

1. As the total sample size increases, the degrees of freedom for the residuals
increases.

2. The constant variance condition can be somewhat relaxed when the sample sizes
are large.

3. The independence assumption can be relaxed when the total sample size is
large.

4. The normality condition is very important when the sample sizes of each 
group are small. 

---

## Group Project

**Detailed instructions can be found on Canvas.** 

---

## Think Out Loud

**Take one concept you have worked on this quarter that you struggled to
understand, and explain how the struggle itself was valuable.**

In the context of this question, describe the struggle and how you overcame the
struggle. You might also discuss whether struggling built aspects of character
in you (e.g. endurance, self-confidence, competence to solve new problems) and
how these virtues might benefit you in later ventures.

