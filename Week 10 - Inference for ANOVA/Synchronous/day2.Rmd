---
title: "`r emo::ji('joker')` Comparison of Multiple Means"
date: "November 30, 2021" 
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["xaringan-themer.css", "slide-style.css"]
    nature:
      highlightStyle: solarized-light
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
---

```{r set-theme, include=FALSE}
library(xaringanthemer)
library(xaringan)
library(knitr)
library(tidyverse)
library(openintro)
library(infer)
library(ggridges)
library(flair)
library(broom)
library(gridExtra)
library(kableExtra)

set.seed(12345)
knitr::opts_chunk$set(warning = FALSE, 
                       message = FALSE, 
                      fig.width = 5, 
                      fig.height = 4, 
                      results = "hold")

options(show.signif.stars = FALSE)

style_duo_accent(
  primary_color      = "#0F4C81", # pantone classic blue
  secondary_color    = "#B6CADA", # pantone baby blue
  header_font_google = google_font("Raleway"),
  text_font_google   = google_font("Raleway", "300", "300i"),
  code_font_google   = google_font("Source Code Pro"),
  text_font_size     = "30px"
)

evals_small <- evals %>% 
  group_by(prof_id) %>% 
  sample_n(size = 1) %>% 
  ungroup()

obs_F <- evals_small %>% 
  specify(score ~ rank) %>% 
  calculate(stat = "F")

null_dist <- evals_small %>% 
  specify(score ~ rank) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 2000, type = "permute") %>% 
  calculate(stat = "F")
```

.huge[Goal]

.large[
- Compare how different a group of means are
- Scale the differences relative to the variability of the groups
- Summarize the differences with one number
]

---

class: middle

.larger[Visualizing Group Differences]

We want visualizations that allow for us to easily compare:  

- the center (mean) of the groups 
- the spread (variability) of the groups 

--

**And also plot the raw data!**

---

class: center 

.larger[Option 1: Side-by-Side Boxplots]

```{r, eval = FALSE}
evals %>% 
  ggplot(aes(x = rank, y = score, fill = rank)) + 
  geom_boxplot(outlier.alpha = NA) + 
  geom_jitter(width = 0.2) + 
  theme(legend.position = "none")
```

```{r, echo = FALSE, out.width = "40%"}
evals %>% 
  ggplot(aes(x = rank, y = score, fill = rank)) + 
  geom_boxplot(outlier.alpha = NA) + 
  geom_jitter(width = 0.2) + 
  theme(legend.position = "none", 
        axis.title = element_text(size = 14), 
        axis.text.x = element_text(size = 12))
```


---

class: center

.larger[Option 2: Stacked Density Plots]

```{r, eval = FALSE}
evals %>% 
  ggplot(aes(y = rank, x = score, fill = rank)) + 
  geom_density_ridges(jittered_points = TRUE, scale = 1) + 
  theme(legend.position = "none") 
```

```{r, echo = FALSE, out.width = "40%"}
evals %>% 
  ggplot(aes(y = rank, x = score, fill = rank)) + 
  geom_density_ridges(jittered_points = TRUE, scale = 1) + 
  theme(legend.position = "none", 
        axis.title = element_text(size = 14), 
        axis.text.y = element_text(size = 12))
```

---

class: center

.larger[Summarizing Group Differences]

```{r, echo = FALSE, fig.width = 10, fig.height = 6, fig.align= 'center'}

overall_mean <- evals_small %>% 
  summarize(mean(score)) %>% 
  pull()

group_means <- evals_small %>% 
  group_by(rank) %>% 
  summarize(mean(score)) %>% 
  pull()

evals %>% 
  ggplot(aes(x = rank, y = score, fill = rank)) + 
  geom_boxplot(alpha = 0.2) + 
  geom_jitter(width = 0.2, alpha = 0.75) +
  geom_hline(yintercept = overall_mean, 
             color = "red", 
             linetype = "dashed", 
             lwd = 1.5) +
  geom_segment(x = 0.5, xend = 1.5, y = group_means[1], yend = group_means[1], 
               color = "blue", lwd = 2, linetype = "dotted") +
  geom_segment(x = 1.5, xend = 2.5, y = group_means[2], yend = group_means[2], 
               color = "blue", lwd = 1.5, linetype = "dotted") +
  geom_segment(x = 2.5, xend = 3.5, y = group_means[3], yend = group_means[3], 
               color = "blue", lwd = 1.5, linetype = "dotted") +
  theme(legend.position = "none", 
        axis.title = element_text(size = 16), 
        axis.text.x = element_text(size = 14))
```

---

class: center

.larger[F-statistic]

Ratio of variability between groups to variability within groups

<center>
.bitlarger[
$\frac{\frac{SSB}{k-1}}{\frac{SSE}{n-k}} = \frac{MSB}{MSE}$
]

**Will an F-statistic ever be negative?**

---

class: center

.larger[Calculating an F-statistic]

.pull-left[
.large[Using `aov()`]

```{r}
aov(score ~ rank, data = evals_small) %>% 
  tidy()
```

]


.pull-right[
.large[Using infer]

```{r}
evals_small %>% 
  specify(score ~ rank) %>% 
  calculate(stat = "F")
```

]

---

class: middle, center

.larger[Hypotheses]

For an ANOVA, we are interested in testing for a difference in multiple groups. 

<center> 

$H_0$: all of the group means are the same 

$H_A$: at least one group mean differs

---

class: middle 

.larger[**Conditions of an ANOVA**]

- Independence 
  * Within groups 
  * Between groups
  
- Normality of the responses
  * The distribution of each group is approximately normal

- Equal variability of the groups 
  * The spread of the distributions are similar across groups
  
---

.larger[**F-distribution**] 

- If the conditions of normality and equal variance are not violated, we can use 
the $F$-distribution to approximate the shape of the true sampling distribution. 

--

- An $F$-distribution is a variant of the $t$-distribution, and is also defined by degrees of freedom. 
  * This distribution is defined by __two__ different degrees of freedom:  
    1. from the numerator (MSG) : $k - 1$
    2. from the denominator (MSE) : $n - k$ 

---

.large[**Visualizing the Observed Statistic**]

<center> 
.midi[
$F$-distribution with 2 and 91 degrees of freedom
]

```{r, echo = FALSE, fig.width = 8, fig.height = 6, fig.align='center'}
values <- rf(100000, df1 = 2, df2 = 91) %>% 
  tibble()

values %>% 
ggplot(aes(x = .)) + 
  geom_density() + 
  xlim(c(0, 5)) + 
  geom_vline(xintercept = 0.546, color = "red", linetype = "dashed") +
  labs(x = "F-statistic", 
       y = "Density")

```

---

class: center 

.larger[**Calculating the p-value**]

Using an F-distribution, the p-value is output from the `aov()` function:


```{r}
aov(score ~ rank, data = evals_small) %>% 
  tidy()
```


---

class: center

.larger[**Simulation-based Methods**]

If the condition of normality is violated, then a simulation-based method would produce a more accurate p-value. 

--

We can use the familiar tools from the infer package, with only one change: the statistic that is calculated! 

```{r, eval = FALSE}
null_dist <- evals_small %>% 
  specify(score ~ rank) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 2000, type = "permute") %>% 
  calculate(stat = "F")
```

---

class: center 

.larger[Visualizing the p-value]


```{r, eval = FALSE}
null_dist %>% 
  visualise() + 
  shade_p_value(obs_stat = obs_F, direction = "greater")
```

```{r, fig.width = 8, fig.height = 5, echo = FALSE}

p_val <- get_p_value(null_dist, obs_stat = obs_F, direction = "greater") %>% 
  pull()
  
null_dist %>% 
  visualise() + 
  shade_p_value(obs_stat = obs_F, direction = "greater") + 
  annotate(x = 2.5, y = 500, geom = "text", label = p_val, size = 6)
```
