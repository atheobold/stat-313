---
title: "Statistical Critique 2: Statistical Argumentation"
subtitle: "Due March 5, 2023 by midnight"
format: 
  html:
    embed-resources: true
    standalone: true
    table-of-contents: true
    toc-depth: 2
    number-sections: true
    number-depth: 1
editor: visual
---

![](significant.jpeg)

## Assignment Details

In your second statistical critique, you will focus on critiquing another key aspect of any statistical argument---statistical significance. No doubt you have seen $p$-values in a previous statistical course and / or disciplinary course, and this week you're adding to that knowledge. For this critique you read about common misinterpretations and misuses of $p$-values, and critique the statistical argumentation used in the article you selected.  

# Part One: Locating Your Article's Statistical Arguments

The focus of this assignment is to critique the statistical argument(s) included in the article you selected. So, you need to first locate these arguments. To do this I recommend the following:

- go to the Results / Findings section
- skim through the section to see where p-values are referenced

::: {.callout-tip}
It is possible the article might not explicitly say the word "p-value", but they could reference $p$ or even just reference an $\alpha$ threshold (likely 0.05).
:::

For Part One, you are required to included the statistical argument(s) from your paper in your critique. To do this you will need to copy-and-paste or type out the statistical argument from your paper. Be sure to use proper citation, to indicate where the excerpt(s) you selected came from. 

# Part Two: Learning More about Misuses of $p$-values

> "The p-value was never intended to be a substitute for scientific reasoning."
> Ron Wasserstein, Executive Director of the American Statistical Association

Issues with the use of $p$-values had gotten so problematic that the American Statistical Association (ASA)^[This is my professional organization.] put out a statement in 2016 titled, ["The ASA Statement on Statistical Significance and $p$-Values"](https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf). This statement includes six principles which address misconceptions and misuse of the $p$-value. 

For this section, you are required to:

1. read the American Statistical Association's statement on $p$-values and statistical significance
2. note what misinterpretations you believe apply your excerpt (from Part One) **and** why

::: {.callout-tip}
# Justification

Note, you are required to *justify* why you believe the selected misinterpretations apply to your article's statistical argument(s).
:::

# Part Three: Learning More about the Backlash Against $p$-values

> "Over time it appears the p-value has become a gatekeeper for whether work is publishable. This apparent editorial bias leads to the
‘file-drawer effect,’ in which research with statistically significant outcomes are much more likely to get published, while other work that might well be just as important scientifically is never seen in print. It also leads to practices called by such names as ‘p-hacking’ and ‘data dredging’ that emphasize the search for small p-values over other statistical and scientific reasoning."
>
> Jessica Utts, President of the American Statistical Association

For Part Two, you are going to inspect what the publication requirements are for journal the article you selected was published in. 

In March of 2019, Valentin Amrhein, Sander Greenland, Blake McShane and more than 800 signatories published an article in Nature [calling for an end to "statistical significance"](https://www.nature.com/articles/d41586-019-00857-9). The article details how, on top of the many common misunderstandings about hypothesis testing and $p$-values, there is an incentive for researchers to "cherry pick" only the results that are "statistically significant" while dismissing those that aren't. There are two problems with this system:

1. it incentivizes researchers to do whatever it takes to obtain "significant" p-values, even through dishonest means
2. it dismisses the importance of results where no "significant" effects are found
 
First, go to the website for the journal where your article was published. Now, find their criteria for publication. If you are having a difficult time finding these criteria, it may be simpler to Google "*title of journal* publication criteria," substituting the name of your journal. 

Search through the criteria and see if there are requirements for (1) the "significance" of the findings and (2) the availability of the data and / or analyses. Describe what you find! 

::: {.callout-tip}
Feel free to type out what you find while searching the journal or simply copy-and-paste the criteria you find listed on their website. 
:::

# Part Four: Improving Statistical Arguments

> "The use of 'significance' in reporting statistical results is fraught with problems—but they could be solved with a simple change in practice."
> Megan Higgs


More and more journals are retiring the use of statistical significance as a requirement for publication, but, sadly, we still see many researchers using the term "statistically significant" in their argumentation. 

For this section you are required to :

- read [*Do We Really Need the S-Word?*](https://www.americanscientist.org/article/do-we-really-need-the-s-word) by Dr. Megan Higgs
- name **at least one** aspect of the interpretation from your article you believe is clear / understandable
- name **at least one** aspect of the interpretation from your article could be improved to be more clear / understandable


