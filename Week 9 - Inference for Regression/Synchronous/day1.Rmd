---
title: "`r emo::ji('scientist')` Inference for Linear Regression"
date: "November 15, 2021" 
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["xaringan-themer.css", "slide-style.css"]
    nature:
      highlightStyle: solarized-light
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# R options
options(
  htmltools.dir.version = FALSE,
  tibble.width = 65,
  width = 65
  )

# figure height, width, dpi
knitr::opts_chunk$set(fig.width = 8, 
                      fig.asp = 0.618,
                      out.width = "60%",
                      dpi = 300, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align = "center",
                      echo = FALSE)

# fontawesome
htmltools::tagList(rmarkdown::html_dependency_font_awesome())

# magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}

# xaringanExtra
library(xaringanExtra)
xaringanExtra::use_panelset()

library(emo)
library(tidyverse)
library(moderndive)
library(openintro)
library(ggridges)
library(flair)
library(broom)
library(gridExtra)
library(kableExtra)
library(infer)

options(show.signif.stars = FALSE)
```

```{r set-theme, include = FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color      = "#b76352", # mango
  secondary_color    = "#34605f", # bayberry
  header_font_google = google_font("Raleway"),
  text_font_google   = google_font("Raleway", "300", "300i"),
  code_font_google   = google_font("Source Code Pro"),
  header_color = "#793540", #rhubarb
  white_color = "#F5F5F5", # lightest color
  black_color = "#36454F", # darkest color
  text_font_size = "30px", 
  link_color = "#696969" #grey
)


evals_small <- evals %>% 
  group_by(prof_id) %>% 
  sample_n(size = 1) %>% 
  ungroup()

obs_slope <- evals %>% 
  specify(score ~ bty_avg) %>% 
  calculate(stat = "slope") %>% 
  pull()

bootstrap_slope <- evals %>% 
  specify(formula = score ~ bty_avg) %>%
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "slope")

null_slope <- evals %>% 
  specify(formula = score ~ bty_avg) %>%
  hypothesise(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope")
```

.huge[you...]

.large[
- know about p-values
- know about confidence intervals
- know about linear regression 
- understand sampling variability
- are interested in making inference about a regression line
]

---

class: middle

.larger[Recall: The `evals` data]

These data contain observations on 463 courses at the University of Texas 
Austin from 94 professors. There were 23 variables recorded in the data:

- information about the course
- information about the professor
- information about number of students 
- information about the "attractiveness" rating of the professor

---

class: center, middle

.larger[Linear Regression]

We modeled the relationship between a professor's evaluation score (`score`)
and their average attractiveness score (`bty_avg`) with linear regression. 

```{r slr-viz, echo = FALSE, fig.width = 16, fig.align='center'}
slr <- evals %>% 
  ggplot(aes(x = bty_avg, y = score)) + 
  geom_jitter() + 
  geom_smooth(method = "lm") + 
  labs(x = "Average Beauty Score (0 to 10)", 
       y = "Course Evaluation Score (1 to 5)")


mlr <- evals %>% 
  ggplot(aes(x = bty_avg, y = score, color = gender)) + 
  geom_jitter() + 
  geom_smooth(method = "lm") + 
  labs(x = "Average Beauty Score (0 to 10)", 
       y = "Course Evaluation Score (1 to 5)", 
       color = "Gender of Professor")

grid.arrange(slr, mlr, widths = c(0.45, 0.55))

```

---

class: center, middle

.larger[And we got our estimated regression equation...]

```{r}
evals_lm <- lm(score ~ bty_avg, data = evals)

evals_lm %>% 
  get_regression_table() %>% 
  kable() %>% 
  kable_styling()

```

---

class: center, middle

> .larger[.bayberry[What parameter are we (typically) interested in for linear
regression?  
What symbol do we use to notate this parameter?]] 

---

class: center, middle, inverse

.huge[.hand[.honey[That slope seems kind of small...]]]

---

class: middle, center

.huge[Hypothesis test]

</br> 

.larger[**What slope would we expect if there was no linear relationship?**]

---

class: center 

.larger[Standard Hypotheses]

.large[$$y = \beta_0 + \beta_1 \times x$$] 

--

.pull-left[
.large[$$ H_0: \beta_1 = 0$$]

There *is no* linear relationship between $x$ and $y$

]

--

.pull-right[
.large[$$H_A: \beta_1 \neq 0$$]

There *is some* linear relationship between $x$ and $y$
]

---

class: center

.larger[**Permutation Distribution for the Slope**]

```{r}
null_slope %>% 
  visualize() +
  labs(x = "Permuted Slope Statistic", 
       title = "") + 
  geom_vline(xintercept = 0,
        color = "blue",
        lty = "dashed", 
        lwd = 1.5)
```

---

class: center

.larger[**p-value for Observed Slope**]

```{r}
null_slope %>% 
  visualize() +
  labs(x = "Permuted Slope Statistic", 
       title = "") + 
  shade_p_value(obs_stat = obs_slope,
                direction = "both", 
                color = "red",
                lty = "dashed")
```

---

class: center, middle, inverse

.huge[.hand[.honey[What would you conclude?]]]

---

class: center, middle

.huge[Confidence interval]

</br>

.larger[**What slopes might we have gotten from other samples?**]

---

class: center

.larger[**Bootstrap Distribution for the Slope**]

```{r}
bootstrap_slope %>% 
  visualize() +
  labs(x = "Bootstrap Slope Statistic", 
       title = "") 
```

---

class: center, middle

> .larger[.bayberry[Where is our bootstrap distribution always centered?]] 

---

class: center 

.larger[**95% Confidence Interval**]

.pull-left[
```{r, out.width = "95%"}
ci <- bootstrap_slope %>% 
  get_confidence_interval(level = 0.95, type = "percentile")

bootstrap_slope %>% 
  visualize() +
  labs(x = "Bootstrap Slope Statistic", 
       title = "") + 
  shade_ci(ci)
```
]

--

.pull-right[
</br>

```{r}
ci %>% 
  kable() %>% 
  kable_styling()
```
]

---

class: middle, center

.huge[But...]

.large[our inferences depend on mathematical conditions.] 

--

.large[For regression, there are four conditions for inference:  

**L**inear relationship  
**I**ndependence of observations  
**N**ormality of residuals  
**E**qual variance of residuals  

]

---

class: center, middle 

.huge[**Exit Ticket**]

.large[For the UT Austin data, while there is data on 463 courses, these 463
courses were actually taught by 94 unique instructors.  

.rhubarb[Is the condition of independence violated? Why or why not?] 
]



