---
title: "Introduction to Visualizing and Summarizing Data"
author: "Taylor Bucher"
date: "Due: January 24, 2021 at 11:59pm"
output: html_document
---


<div style="color:blue">

Great job! You have revisions on problems: 

My comments for your responses to the exercises can be found in blue text, and my comments/suggestions for your R code can be found in the code chunks behind two hashtags (##)

Your homework assignment receives a score that reflects the average points-per-question, where each question is worth 4 points. This is assigned based on the grading system outlined in the syllabus. 

Problems marked with an “R” must be redone and returned within two days of receiving the assignment back. You will receive a score of 0 on each problem requiring a revision until a revision is submitted. Late revisions receive a zero, unless you contact me. Work successfully redone (on time) will receive a maximum grade of 3. It is possible to have a redo on a redo.

</div>


```{r, include = FALSE}
knitr::opts_chunk$set(echol = TRUE, 
                      results = "hold", 
                      message = FALSE, 
                      warning = FALSE)
```

## Getting started

### Load packages

In this lab, we will explore and visualize the data using the **tidyverse** suite of packages. The data can be found in the companion package for OpenIntro labs, **openintro**.

Let's load the following packages:

-   The **tidyverse** "umbrella" package which houses a suite of many different `R` packages: for data wrangling and data visualization
-   The **openintro** `R` package: for data and custom functions with the OpenIntro resources

```{r, include = FALSE}
library(tidyverse)
library(openintro)
## This is a comment -- R will not run this line as code, because it has ## before it
```

### The data

The [Bureau of Transportation Statistics](http://www.rita.dot.gov/bts/about/) (BTS) is a statistical agency that is a part of the Research and Innovative Technology Administration (RITA).
As its name implies, BTS collects and makes transportation data available, such as the flights data we will be working with in this lab.

First, we'll view the `nycflights` data frame.
Type the following in your console to load the data:

```{r}
data(nycflights)
```

The data set `nycflights` that shows up in your workspace is a *data matrix*, with each row representing an *observation* and each column representing a *variable*.
R calls this data format a **data frame**, which is a term that will be used throughout the labs.
For this data set, each *observation* is a single flight.

To view the names of the variables, you can use the `names()` function: 

```{r}
names(nycflights)
```

This returns the names of the variables in this data frame.
The **codebook** (description of the variables) can be accessed by pulling up the help file by typing a `?` before the name of the dataset:

```{r, eval = FALSE}
?nycflights
```

One of the variables refers to the carrier (i.e. airline) of the flight, which is coded according to the following system.

-   `carrier`: Two letter carrier abbreviation.

    -   `9E`: Endeavor Air Inc.
    -   `AA`: American Airlines Inc.
    -   `AS`: Alaska Airlines Inc.
    -   `B6`: JetBlue Airways
    -   `DL`: Delta Air Lines Inc.
    -   `EV`: ExpressJet Airlines Inc.
    -   `F9`: Frontier Airlines Inc.
    -   `FL`: AirTran Airways Corporation
    -   `HA`: Hawaiian Airlines Inc.
    -   `MQ`: Envoy Air
    -   `OO`: SkyWest Airlines Inc.
    -   `UA`: United Air Lines Inc.
    -   `US`: US Airways Inc.
    -   `VX`: Virgin America
    -   `WN`: Southwest Airlines Co.
    -   `YV`: Mesa Airlines Inc.

Remember that you can use `glimpse` to take a quick peek at your data to understand its contents better.

```{r}
glimpse(nycflights)
```

1. (a) How large is the `nycflights` dataset? (i.e. How many rows and columns does it have?)
<!-- Your response goes below this line! -->

The dataset has 32,735 rows and 16 columns. 

<div style="color:blue">
Correct! 
</div>

1. (b) When were these data collected? 
<!-- Your response goes below this line! -->

2013

<div style="color:blue">
Correct! Did you use the help file? 
</div>


1. (c) Are there categorical variables in the dataset? If so, what are their names and data types? 
<!-- Your response goes below this line! -->

Yes many of these variables are categorical and nominal: year, month, carrier, tailnum, flight, origin, dest, 

<div style="color:blue">
Nice work! Keep in mind that if these variables were labeled a `fct` that would *also* be a categorical variable! Is year considered to be a categorical variable? 
</div>

<div style="color:blue">
Overall: 4
</div>


### Departure Delays

Let's start by examining the distribution of departure delays of all flights with a histogram.

```{r}
ggplot(data = nycflights, aes(x = dep_delay)) +
  geom_histogram(binwidth = 15)
```

This function says to plot the `dep_delay` variable from the `nycflights` data frame on the x-axis.
It also defines a `geom` (short for geometric object), which describes the type of plot you will produce.

Histograms are generally a very good way to see the shape of a single distribution of numerical data, but that shape can change depending on how the data is split between the different bins.
You can easily define the binwidth you want to use, by specifying the `binwidth` argument to `geom_histogram()`, like so:

```{r}
ggplot(data = nycflights, aes(x = dep_delay)) +
  geom_histogram(binwidth = 15)

ggplot(data = nycflights, aes(x = dep_delay)) +
  geom_histogram(binwidth = 150)
```

2.  Look carefully at these three histograms. How do they compare? Are features revealed in one that are obscured in another?
<!-- Your answer goes below this line -- do not remove this!  -->

Looking at the three histograms there are differences between them and it highlights the importance of the feature of binwidth. When the binwidth is increase, there is also an increase in the count as well as the dep_delay. This is important to note because as you increase the binwidth, the relationship is shown more accurately. When the binwidth was low it seemed as if there were not that many counts of delayed departure, but with the binwidth high we could see that there are more delays than originally anticipated.

<div style="color:blue">
Careful! There are the **same** number of observations in each histogram, so the counts are not increasing. What is changing to make the y-axis counts increase whe n moving from one bin size to another?   
</div>

<div style="color:blue">
Overall: Redo
</div>

3. A histogram is only one way to visualize the distribution of a numerical variable. 
(a) What are other visualizations that we could have produced? 
(b) What are the benefits and weaknesses of a histogram compared to these other options? 
<!-- Your response goes below this line! -->

Other visualizations that we could have produced instead of a histogram are a dotplot or a density plot. Histograms are commonly used in stats because of the many benefits it has. Another benefit is that it is very easy to compare data to one another. Another major reason a histogram is used over a dotplot is that is resolves the issue of confusion that a dotplot gets near the x and y-axis. It solves this issue by aggregating the dots into bins and then mapping the height of the bar to the number of cases that fall into that bin on the x-axis. Although histograms have this feature, this style of visualization still has weaknesses. A major one being that histograms cannot perfectly reconstruct a dataset, but it can give a bigger picture of the shape of the relationship and distribution. Another disadvantage of these can be seen with the example from earlier that data can be misleading. If we did not alter the binwidth then we would have been mislead about the actual relationship between those variables. 

<div style="color:blue">
Great description of the benefits of the different plotting options! Why would we choose a histogram over a boxplot? 
</div>

<div style="color:blue">
Overall: 4
</div>


## LAX Destinations 

If you want to visualize only on delays of flights headed to Los Angeles, you need to first `filter()` the data for flights with that destination (`dest == "LAX"`) and then make a histogram of the departure delays of only those flights.

```{r}
lax_flights <- nycflights %>%
  filter(dest == "LAX")

ggplot(data = lax_flights, aes(x = dep_delay)) +
  geom_histogram()
```

Let's decipher these two commands (OK, so it might look like four lines, but the first two physical lines of code are actually part of the same command. It's common to add a break to a new line after `%>%` to help readability).

-   Command 1: Take the `nycflights` data frame, `filter()` for flights headed to LAX, and save the result as a new data frame called `lax_flights`.

    -   `==` means "if it's equal to".
    -   `LAX` is in quotation marks since it is a character string.

-   Command 2: Basically the same `ggplot()` call from earlier for making a histogram, except that it uses the smaller data frame for flights headed to LAX instead of all flights.

**Logical operators:** Filtering for certain observations (e.g. flights from a particular airport) is often of interest in data frames where we might want to examine observations with certain characteristics separately from the rest of the data.
To do so, you can use the `filter()` function and a series of **logical operators**.
The most commonly used logical operators for data analysis are as follows:

-   `==` means "equal to"
-   `!=` means "not equal to"
-   `>` or `<` means "greater than" or "less than"
-   `>=` or `<=` means "greater than or equal to" or "less than or equal to"


4. You learned in the tutorial that this process of creating a new dataset based on a filter is not necessarily the best plan. An alternative plan is to use the pipe operator (`%>%`) to create a data pipeline, carrying the filtered data into the plot. 
Change the code below, so it uses the pipe operator instead of saving a new dataset. 

```{r}
## For this exercise, you need to change the code below! 
nycflights %>%
  filter(dest == "LAX") %>%
  ggplot(aes(x = dep_delay)) +
  geom_histogram()

```

<div style="color:blue">
Great use of the pipe operator!
</div>

<div style="color:blue">
Overall: 4
</div>


### Multiple Data Filters 

You can also filter based on multiple criteria.
Suppose you are interested in flights headed to San Francisco (SFO) in February:

```{r}
sfo_feb_flights <- nycflights %>%
  filter(dest == "SFO", month == 2)
```

Note that you can separate the conditions using commas if you want flights that are both headed to SFO **and** in February.
If you are interested in either flights headed to SFO **or** in February, you can use the `|` instead of the comma.


5.  Find the number of flights in this dataset that were headed to SFO in February. 
**Hint:** The `filter()` and `count()` functions will be helpful!  

```{r}
## Code for exercise 1 here! 
sfo_feb_flights <- nycflights %>%
  filter(dest == "SFO", month == 2)
  count(sfo_feb_flights)
## When you don't have a line between the two parts of your code, I assume that they are connected! 
```
<div style="color:blue">
Nice work! You didn't need to store the filtered data in a new dataset. If you used just a "plain" `count()` at the end, it would only output the 68 (because it is counting the rows in the dataset). 
</div>

<div style="color:blue">
Overall: 4
</div>

## Data Summaries 

You can also obtain numerical summaries for the flights headed to LAX, using the `summarise()` function:

```{r}
lax_flights %>%
  summarise(mean_dd   = mean(dep_delay), 
            median_dd = median(dep_delay), 
            n         = n())
```

Note that in the `summarise()` function you created a list of three different numerical summaries that you were interested in.
The names of these elements are user defined, like `mean_dd`, `median_dd`, `n`, and you can customize these names as you like (just don't use spaces in your names).
Calculating these summary statistics also requires that you know the summary functions you would like to use. 

**Summary statistics:** Some useful function calls for summary statistics for a single numerical variable are as follows:

-   `mean()`: calculates the average
-   `median()`: calculates the median
-   `sd()`: calculates the standard deviation
-   `var()`: calculates the variances
-   `IQR()`: calculates the inner quartile range (Q3 - Q1)
-   `min()`: finds the minimum 
-   `max()`: finds the maximum
-   `n()`: reports the sample size

Note that each of these functions takes a single vector as an argument and returns a single value.

## Data Summaries & Data Visualizations 

6.  Describe the distribution of the **arrival** delays of the LAX flights using a histogram and appropriate summary statistics.
**Hint:** The summary statistics you use should depend on the shape of the distribution.
<!-- Your response to this problem goes below this line! -->

Looking at the histogram, the shape and distribution of the arrival delays of LAX flights is unimodal and right skewed. The summary statistic I calculated was the median because when the distribution is skewed, it is better to use the median than other summary statistics. The distribution and the summary statistic are implicating that LAX typically has early arrivals rather than arrival delays since the majority of flights to LAX are closer to zero or negative.


```{r}
## Code for exercise 2 goes here! 

qplot(x = arr_delay, data = lax_flights, geom = "histogram", binwidth = 30)

lax_flights %>%
summarise(median(arr_delay))
```

<div style="color:blue">
Great description of the choice of the median. What other statistics would you calculate? 
In this course we are learning `ggplot()` for making data visualizations, not `qplot()`. I cannot offer you support for these visualizations, because I am not familiar with them. I would **strongly** recommend sticking with the tools we use in class. 
</div>

<div style="color:blue">
Overall: 3
</div>

<div style="color:blue">
Nice work! Great visualization and data summaries! See my comments in your code. 
Excellent choice of data summaries based on the skewed distribution of arrival delays! 
</div>

<div style="color:blue">
Overall: 4
</div>


## Grouped Summaries 

Another useful technique is quickly calculating summary statistics for various groups in your data frame.
For example, we can modify the above command using the `group_by()` function to get the same summary stats for each origin airport:

```{r}
sfo_feb_flights %>%
  group_by(origin) %>%
  summarise(median_dd = median(dep_delay), 
            iqr_dd = IQR(dep_delay), 
            n_flights = n())
```

Here, we first grouped the data by `origin` and then calculated the summary statistics.

## Summaries vs. Visualizations 

Which month would you expect to have the highest average delay departing from an NYC airport?

Let's think about how you could answer this question. 
One option is to summarize the data and inspect the output. 
Another option is to plot the delays and inspect the plots. 
Let's try both! 

7. Find the average departure delays for each month, and arrange these average delays in descending order. 
**Hint:** the `desc()` function is helpful for arranging numbers in descending order! 

```{r}
## Code for exercise 3 goes here! 

nycflights %>%
  group_by(month) %>%
  summarise(mean_dd = mean(dep_delay)) %>%
  arrange(desc(mean_dd))

```

<div style="color:blue">
Nice work combining all of these pieces together! Woohoo! Data rodeo! 
</div>

<div style="color:blue">
Overall: 4
</div>


8. Now, plot the distribution of departure delays, faceted by the month of departure. 
Choose the type of plot you believe is appropriate for visualizing the distribution of departure delays. 

```{r}
## Code for exercise 4 goes here! 

ggplot(nycflights, aes(x = factor(month), y = dep_delay)) +
  geom_boxplot()

```

<div style="color:blue">
This is only one plot of the distribution of departure delays, not faceted by month. 
</div>

<div style="color:blue">
Overall: Redo
</div>

9. What information can you obtain from the visualization that you could not from the data summaries?   
<!-- Your response to this question goes below this line!  -->

From the visualization you can see that there are a few months that have many outliers that may be altering the data. For example, looking at April (4) and July (7) on the boxplot looks like they would have a similar mean, but when looking at the datatable created, the means are very different and July has a much higher mean. The visualization makes the means look much closer together than the table we generated does. 
A trend I am picking up on from the visualization I did not see from the datatable is that near the holidays and summer are the most likely for delays. This could be because people are more likely to have time off so more people are traveling all together increasing the likelihood of a delay.
