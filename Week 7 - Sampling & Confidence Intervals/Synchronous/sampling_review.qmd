---
title: "Sampling Variability -- The Heart of Inference"
format: 
  revealjs:
    self-contained: true
editor: visual
---

```{r set-up}
library(tidyverse)
library(infer)
library(scales)
library(stringr)
```

::: {style="font-size: 3em; color: #000000;"}
Salaries of football coaches
:::

![](images/football.PNG)

```{r data}

coaches <- read_csv(here::here("Week 7 - Sampling & Confidence Intervals", 
                               "Synchronous", 
                               "data", 
                               "cu_csu_coaches.csv")
                    ) %>% 
  filter('Base Pay' > 0)

csu <- coaches %>% 
  filter(Agency == "California State University")

uc <- coaches %>% 
  filter(Agency == "University of California")

```

##

::: {style="font-size: 2em; color: #000000;"}
In your team...
:::

::: columns
::: {.column width="45%"}

::: {style="font-size: 2em; color: #000000;"}
**First**
:::

- sample 10 salaries 
- calculate the median
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}

::: {style="font-size: 2em; color: #000000;"}
**Then**
:::

- sample 25 salaries 
- calculate the median

:::
:::

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
You have a sample of 25 UC & CSU coach salaries.
:::

. . .

</br>

Would you feel comfortable inferring that the median salary of your
sample is close to the median salary of *all* UC & CSU coaches?

. . .

</br>

<center>

Why or why not?

##

::: {style="font-size: 3em; color: #0F4C81;"}
**Why sample more than once?**
:::

. . .

Variability is a central focus of the discipline of ***Statistics***!

. . .

Making decisions based on limited information is uncomfortable!

. . .

> You likely weren't willing to infer the population median salary from your
> sample! 


##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
Sampling Framework
:::

*population* -- collection of observations / individuals we are interested in  

*population parameter* -- numerical summary about the population that is unknown
but you wish you knew  

. . .

</br>

*sample* -- a collection of observations from the population  

*sample statistic* -- a summary statistic computed from a sample that 
*estimates* the unknown population parameter.

##

::: {style="font-size: 2em; color: #000000;"}
Statistical Inference
:::

There were `r nrow(coaches)` "Head Coaches" at University of California and
California State Universities in 2019

</br>

::: columns
::: {.column width="45%"}
```{r}
coaches %>% 
  summarize(median = median(`Total Pay & Benefits`)) %>% 
  mutate(median = 
           str_c("$",
                 str_sub(median, start = 1, end = 3), 
                 ",",
                 str_sub(median, start = 4, end = 6)
                 )
         ) %>% 
  knitr::kable(col.names = "Median salary for all coaches") %>% 
  kableExtra::kable_styling()
```

:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
Inferring information from your sample onto the population is called
**statistical inference**. 
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
Statistical Inference Reasoning
:::


- If the sampling is done at random
- the sample is representative of the population
- any result based on the sample can generalize to the population
- the point estimate is a “good guess” of the unknown population parameter

##  {background-color="#B6CADA"}

</br>
</br>

::: {style="font-size: 2em; color: #000000;"}
Shouldn't one random sample be enough then? Isn't that what we use to make confidence intervals and do hypothesis tests?
:::

## 

::: {style="font-size: 2em; color: #000000;"}
Virtual Sampling
:::


```{r rep-sample-code}
#| echo: true
#| eval: false
#| code-line-numbers: false

rep_sample_n(coaches, 
             size = 25, 
             reps = 1, 
             replace = TRUE)
```

</br>

::: {style="font-size: 0.65em; color: #000000;"}
```{r rep-sample-coaches}
#| echo: false
coaches %>% 
  slice_sample(n = 25) %>% 
  head() %>% 
  select(`Employee Name`, `Job Title`, `Total Pay & Benefits`) %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling()

```
:::

<center>

$\vdots$

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
Distribution of 1000 medians from samples of 25 coaches
:::

```{r samps-of-different-sizes}
#| cache: true

virtual_samples25 <- coaches %>% 
  rep_sample_n(size = 25, reps = 1000)

virtual_med25 <- virtual_samples25 %>% 
  group_by(replicate) %>% 
  summarize(median = median(`Total Pay & Benefits`)) %>% 
  mutate(samps = "25")

virtual_samples50 <- coaches %>% 
  rep_sample_n(size = 50, reps = 1000)

virtual_med50 <- virtual_samples50 %>% 
  group_by(replicate) %>% 
  summarize(median = median(`Total Pay & Benefits`)) %>% 
  mutate(samps = "50")

virtual_samples100 <- coaches %>% 
  rep_sample_n(size = 100, reps = 1000)

virtual_med100 <- virtual_samples100 %>% 
  group_by(replicate) %>% 
  summarize(median = median(`Total Pay & Benefits`)) %>% 
  mutate(samps = "100")

master_samples <- bind_rows(virtual_med25, 
                            virtual_med50, 
                            virtual_med100) 
```

```{r samp-25-plot}
#| out-width: 60%

master_samples %>% 
 filter(samps == "50") %>% 
  ggplot(mapping = aes(x = median)) + 
  geom_histogram(binwidth = 6500, color = "white") + 
  scale_x_continuous(labels = comma) + 
  labs(x = "Median Salary")

```

## 

::: {style="font-size: 2em; color: #000000;"}
Sampling Distributions
:::

- Visualize the effect of sampling variation on the distribution of any point
estimate
  * In this case, the sample median
  
- We can use sampling distributions to make statements about what values we can
typically expect.

. . .

<center> 
Be careful! A **sampling distribution** is different from a *sample's
distribution*! 

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
Distributions of 1000 medians from different sample sizes
:::

```{r samp-plots}
#| fig-align: center

master_samples %>% 
  mutate(samps = factor(samps, 
                        levels = c("25", "50", "100")
                        )
         ) %>% 
  ggplot(mapping = aes(x = median)) + 
  geom_histogram(binwidth = 6500, color = "white") + 
  facet_wrap(~samps) + 
  scale_x_continuous(labels = comma) + 
  labs(x = "Median Salary") +
  theme(axis.text.x = element_text(hjust = 1, 
                                   vjust = 1, 
                                   angle = 45))

```

<center>

**What differences do you see?**

##

::: {style="font-size: 1.75em; color: #000000;"}
Variability for Different Sample Sizes
:::

::: {style="font-size: 0.85em; color: #000000;"}
```{r sd-comparison-table}
#| echo: false

master_samples %>% 
  mutate(samps = factor(samps, levels = c("25", "50", "100")
                           )
         ) %>%
  group_by(samps) %>% 
  summarize(sd = sd(median)) %>% 
  knitr::kable(col.names = c("Sample Size", 
                             "Standard Error of Median")
               ) %>% 
  kableExtra::kable_styling()
  
```
:::

. . .

::: {style="font-size: 0.85em; color: #000000;"}

- Standard errors quantify the variability of point estimates

- As a general rule, as sample size increases, the standard error decreases.
:::

. . .

<center>

::: {style="font-size: 0.85em; color: #000000;"}
Careful! There are important differences between **standard errors**
and *standard deviations*. 
:::

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
A good guess?
:::


```{r samp-plots-true-value}
#| out-width: 70%
master_samples %>% 
  mutate(samps = factor(samps, 
                        levels = c("25", "50", "100")
                           )
         ) %>% 
  ggplot(mapping = aes(x = median)) + 
  geom_histogram(binwidth = 6500, color = "white") + 
  geom_vline(xintercept = median(coaches$`Total Pay & Benefits`), 
             color = "red", 
             linewidth = 1.5) +
  facet_wrap(~samps, ) + 
  scale_x_continuous(labels = comma) + 
  labs(x = "Median Salary")

```

##

::: {style="font-size: 2em; color: #000000;"}
Precision & Accuracy
:::

::: columns
::: {.column width="55%"}
![](images/accuracy_vs_precision.jpg)
:::

::: {.column width="5%"}
:::

::: {.column width="40%"}
- Random sampling ensures our point estimates are accurate.

</br>

- Larger sample sizes ensure our point estimates are precise. 

:::
:::


##  {background-color="#B6CADA"}

::: {style="font-size: 4em; color: #000000;"}
Sampling Activity!
:::
